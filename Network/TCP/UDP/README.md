# TCP UDP

4계층 Transport Layer에 해당하는 통신 프로토콜에는 TCP와 UDP가 있다.

TCP와 UDP는 신뢰성과 신속성으로 분류할 수 있다.

데이터를 주고 받는 것이 중요하다면 **TCP**를,

데이터를 주고 받는 것 보다, 빠르게 보내는 것이 중요하다면 **UDP**를 사용하면 된다.

지금부터 각각의 프로토콜에 대해서 좀 더 자세히 알아보자

## TCP

TCP의 특징은 다음과 같다.

- 연결 지향
- 신뢰성있는 데이터 전송
- 흐름제어
- 혼잡 제어

지금부터 하나씩 알아보자

### 연결 지향

TCP는 연결지향 프로토콜이다.

이 말은 프로토콜에 의해 연속적인 패킷의 상태 정보를 확인하고 유지하는 것을 기본으로 한다는 것을 알 수 있다.

따라서, 장치간의 **연결**에 관한 세션을 수립하는 과정이 매우 중요하다.

이 과정을 우리는 **TCP-3-way-handshake**라고 부른다.

![99087C405C18E3CD28](https://user-images.githubusercontent.com/43809168/72984139-51c89280-3e26-11ea-9d2c-ca8633cccbed.png)

마치 악수를 하듯이 세번의 과정을 거쳐서 연결을 수립할 수 있다.

1. 클라이언트는 서버에게 접속 요청 메세지 SYN을 전송하고 SYN_SENT 상태가 된다. a를 보냈다.

2. 서버는 SYN 요청을 받고 클라이언트에게 요청 수락 (SYN + ACK) 하고 SYN_RECEIVED 상태가 된다. SYN(b) + ACK(a+1)를 응답한다.

3. 클라이언트는 서버에게 수락 확인 ACK(b+1)을 보내고 서버는 ESTABLESHED 상태가 된다.

이러한 3-way-handShake와 과정을 거쳐서 신뢰성 있는 연결을 보장할 수 있게 되는 것이다.

3-way-handShake와 마찬가지로, 접속 상태를 **해제**하기 위한 과정 또한 필요한데, 

이를 **4-way-handshake**라고 부른다.

![스크린샷 2020-01-23 오후 9 25 37](https://user-images.githubusercontent.com/43809168/72984379-ea5f1280-3e26-11ea-9861-220997955356.png)

총 4번의 과정을 거친다.

1. 클라이언트가 FIN 요청을 보낸다.

2. 서버가 응답(ACK) 을 보낸다.

3. 잠시 후 서버는 close를 하고 FIN을 보낸다.

4. 클라이언트는 ACK를 서버에게 보내고, 서버는 CLOSED 상태가 된다.

5. 이 후 클라이언트는 어느정도 시간이 흐른 뒤에 CLOSED 상태로 바뀐다. 기다리는 이유는 혹시나 서버에서 미처 보냈는데 도착하지 못한 패킷이 있을 지 모르기 때문에 그것들을 받아주기 위해서 ACK를 보내고 나서도 조금 더 기다렸다가 CLOSE 상태가 된다.

### 신뢰성 있는 데이터 전송

신뢰성 있는 데이터를 전송하기 위해 조금은 복잡한 일련의 프로토콜을 소개한다.

#### RDT 1.0 (Reliable Data Transfer)

![스크린샷 2020-01-23 오후 9 35 40](https://user-images.githubusercontent.com/43809168/72985025-66a62580-3e28-11ea-999a-2117171d97fa.png)

이 프로토콜은 단순하다.

하위 채널이 완전히 신뢰적인 경우를 고려하는 것이다.

RDT 1.0은 송신자와 수신자에 대한 유한 상태머신이다.

a는 송신자, b는 수신자의 동작을 정의한다.

시나리오는 간단하다.

1. 송신측에서 패킷을 만들고 패킷을 수신자에게 보냄

2. 수신자는 패킷을 받으면 데이터를 추출하고 데이터를 상위 계층에 전달함.

#### RDT 2.0

비트 오류가 있는 채널 상에서의 신뢰적 데이터 전송에 대한 모델이다.

RDT 2.0에서는 데이터 채널의 비트 오류를 확인하기 위해 긍정 확인 응답과 부정 응답 확인을 사용한다.

이러한 제어 메세지는 정확하게 수신되었는지 또는 잘못 수신되어 반복이 필요한지를 수신자가 송신자에게 알려줄 수 있게 한다.

컴퓨터 네트워크에서는 이러한 재전송 기반 데이터 전송 프로토콜을 **자동 재전송 요구 프로토콜 Automatic Repeat reQuest**라고 하며 줄여서 ARQ라고 부른다.

![스크린샷 2020-01-23 오후 9 42 41](https://user-images.githubusercontent.com/43809168/72985427-4c207c00-3e29-11ea-807b-d70bf573abff.png)

2.0에서는 송신자 측이 2개의 FSM을 갖는다.

송신자는 상위 계층으로 부터 데이터가 전달되기를 기다린다.

rdt_send()가 호출되면 송신자는 패킷 CheckSum과 함께 전송될 데이터를 포함하는 패킷(sndpkt)을 생성하고, 그 패킷을 udt_send 동작을 통해 전송한다.

그 후 송신자 프로토콜은 수신자로 부터 ACK or NAK 응답을 기다린다.

만약 ACK가 수신된다면 마지막에 보낸 패킷이 정확하게 수신되었다는 뜻이고 NAK가 수신되면 프로토콜은 마지막 패킷을 재전송하고 재전송된 패킷에 ACK or NAK를 기다린다.

단, 이때 ACK 또는 NAK를 기다리는 수신 대기상태에서는 상위 계층으로 부터 더 이상 데이터를 받을 수 없다.

즉 rdt_send()가 재전송의 응답을 기다리는 동안에 발생하지 않는다.

그래서 rdt2.0 프로토콜은 전송 후 대기(Stop-and-Wait) 프로토콜로 알려져 있다.

rdt2.0은 비트 오류를 검출하고 재전송하여 완벽한 것 같지만 치명적 약점이 존재한다.

바로 ACK or NAK가 손상될 수 있다는 점이다.

이러한 오류를 검출하기 위해 ACK와 NAK에 대한 CheckSum bit를 추가할 필요가 생긴다.

#### RDT 3.0

3.0는 두가지 문제를 해결하고자 했다.

1. 어떻게 패킷 손실을 검출할 것인가
2. 손실이 발생했을 때 어떤 행동을 취할 것인가

지금부터 3.0은 이를 어떻게 극복하였는지 알아보자

패킷 손실 검출을 위해서는 새로운 매커니즘을 추가해야 했다.

이를 위해 sender는 합리적인 시간만큼 ACK를 기다린다.

만약 기다렸는데도 ACK가 안온다면? 재전송을 한다.

만약 RTT가 합리적인 시간보다 길어진 경우라면?

즉, ACK가 지연된 것이라면 Receiver는 중복된 Packet을 받게 된다.

하지만 이 중복 데이터는 Sequence Number를 이용하면 중복데이터 처리가 가능하며 이는 rdt.0을 발전시킨 rdt.2에서 이미 구현하였다.

그래서 이러한 재전송을 하기 위해 **Countdown Timer**라는 개념을 만들었다.

송신자는 다음과 같이 동작한다.

1. 모든 패킷은 송신된 시간에 타이머를 시작한다.

2. 타이머 인터럽트에 반응하고 인터럽트 루틴을 처리한다.

3. 타이머를 멈춘다.

![스크린샷 2020-01-23 오후 9 56 35](https://user-images.githubusercontent.com/43809168/72986291-3e6bf600-3e2b-11ea-826e-7b1e1628319a.png)

### 흐름 제어

송신측과 수신측이 데이터를 주고 받을 때, 여러가지 요인으로 둘의 처리속도가 달라질 수 있다.

이 때 데이터를 받는 수신측의 처리 속도가 송신 측보다 빠른 경우는 크게 문제될 일이 없다.

그러나 반대로 송신측의 처리 속도보다 수신측의 전송 속도가 빠르다면, 수신측의 버퍼가 가득찬 상황에서 데이터는 폐기처분된다.

송신측에서 이를 알고 다시 데이터를 보내주긴 하겠지만, 네트워크 환경에서 이러한 과정은 가능하면 줄일 수 있는게 좋다.

이러한 수신측의 데이터 처리속도를 파악해 얼마나 빠르게, 많은 데이터를 처리할지 결정해야하는데 이것이 바로 TCP의 흐름 제어인 것이다.

즉, **송신측은 수신측이 알려준 윈도우 크기와 네트워크 상황을 고려해 윈도우 송신 측 윈도우 크기를 결정한다.**

흐름 제어 방법에는 Stop-and-Wait와 Sliding Window 두가지 방식이 존재한다.

#### Stop and Wait

![stop-and-wait](https://user-images.githubusercontent.com/43809168/72992472-200bf780-3e37-11ea-84d5-efbe3c91cdbd.png)

어찌 보면 가장 단순한 방법이다.

이름 그대로 데이터를 주고, ACK를 받을 때 까지 기다리는 방식이다.

문제는 이러한 경우 방식이 간단한 만큼 비효율 적이다.

왜냐하면 송신측은 자신이 직접 데이터를 보내봐야 이 데이터를 수신측이 처리할 수 있는지 알 수 있기 때문이다.

그래서 이 방식은 잘 사용을 안한다.

#### Sliding Window

![스크린샷 2020-01-23 오후 11 24 21](https://user-images.githubusercontent.com/43809168/72992670-8264f800-3e37-11ea-806e-30b9337c438c.png)

오늘날의 TCP는 대부분 흐름제어 방식에 Sliding Window 기법을 사용한다.

슬라이딩 윈도우는 수신 측이 한 번에 처리할 수 있는 데이터를 정해놓고, 그때 그때 수신측의 데이터 처리 상황을 송신측에 알려줘서 데이터의 흐름을 제어하는 방식이다.

둘의 가장 큰 차이점은 **수신(Sender)측이 송신(Receiver)측에서 얼마만큼의 데이터를 처리할 수 있는지를 이미 알고 있다는 점**이다.

실제 환경에서 TCP의 최대 윈도우 크기는 65,535 bytes 이고 WSCALE 옵션을 최대로 적용하면 1GB까지도 가능하다고 하니,

연속적으로 한번에 보내는 데이터도 이정도 단위로 보내고 받는다면 굉장히 좋은 효율을 뽑아낼 수 있다.

이론적으로는 수신측의 ACK 응답 없이도 최대 1GB를 연속적으로 전송할 수 있다는 의미이기도 하다.

### 혼잡 제어

송신측의 데이터는 지역망이나 인터넷으로 대형 네트워크를 통해 전달된다.

만약 하나의 라우터에 대량의 데이터가 몰린다면 어떻게 될까?

자신에게 온 모든 데이터를 처리 할 수 없을 것이다.

이런 경우 호스트들은 다시 재전송을 할 것이고, 이는 혼잡을 가중시켜 데이터 손실을 유발하게 될 것이다.

TCP에서는 네트워크 내에 패킷의 수가 과도하게 증가하는 혼잡현상을 방지하거나 제어하는 기능을 갖고 있다.

앞서 봤던 흐름 제어를 할때 송신측의 윈도우 크기는 수신측이 보내준 윈도우 크기와 네트워크 상황을 고려해 정해진다고 하였다.

송신 측은 자신의 최종 윈도우 크기를 정할 때 수신 측이 보내준 윈도우 크기인 **수신자 윈도우 RWND**와 네트워크 상황을 고려해 정한 윈도우 크기인 **혼잡 윈도우 CWND** 중 더 작은 값을 선택한다.

여기서는 혼잡 회피를 하기 위한 방법과 혼잡 제어 정책에 어떤 것이 있는지 살펴보도록 하자.

#### 혼잡 회피

##### AIMD

Additive Increase / Multicative Decrease 방식은 우리 말로 직역하면 합 증가 / 곱 감소 방식이라는 뜻이다.

즉 네트워크가 충분히 혼잡하지 않을 때는 혼잡 윈도우의 크기를 1씩 증가시키다가 줄어들 때는 1/2로 줄어들게 하는 것이다.

이름 그대로 **합 증가 / 곱 감소**인 것이다.

이러한 방식은 늘어날때는 선형적으로 늘어나다가, 줄어들 때는 반으로 확 줄어들 것이다.

![스크린샷 2020-01-23 오후 11 41 08](https://user-images.githubusercontent.com/43809168/72994087-da046300-3e39-11ea-823a-06a14a0f822e.png)

그래서 이는 위와 같은 형태를 보인다.

## Reference

https://sjlim5092.tistory.com/entry/tcp-3-way-handshake-%EB%82%B4%EC%9A%A9-%EC%A0%95%EB%A6%AC

https://lkhlkh23.tistory.com/130?category=833712

https://rain-bow.tistory.com/entry/%EC%8B%A0%EB%A2%B0%EC%A0%81%EC%9D%B8-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%86%A1-RDT-102030

https://evan-moon.github.io/2019/11/22/tcp-flow-control-error-control/

https://www.slideshare.net/GondweBenard/module15